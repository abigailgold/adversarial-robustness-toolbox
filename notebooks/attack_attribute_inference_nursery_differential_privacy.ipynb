{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running attribute inference attacks on regular and differentially private models created using DiffPrivLib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show how to run attribute inference attacks on models trained using differential privacy. This will be demonstarted on the Nursery dataset (original dataset can be found here: https://archive.ics.uci.edu/ml/datasets/nursery), with a Naive Bayes classifier trained using the IBM Differential Privacy Library (https://github.com/IBM/differential-privacy-library).\n",
    "\n",
    "The sensitive feature we are trying to infer is the 'social' feature, after we have turned it into a binary feature (the original value 'problematic' receives the new value 1 and the rest 0).\n",
    "\n",
    "To run this example you must first install DiffPrivLib by running: pip install diffprivlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>children</th>\n",
       "      <th>social</th>\n",
       "      <th>parents_pretentious</th>\n",
       "      <th>parents_great_pret</th>\n",
       "      <th>parents_usual</th>\n",
       "      <th>has_nurs_very_crit</th>\n",
       "      <th>has_nurs_improper</th>\n",
       "      <th>has_nurs_proper</th>\n",
       "      <th>has_nurs_critical</th>\n",
       "      <th>...</th>\n",
       "      <th>form_incomplete</th>\n",
       "      <th>form_foster</th>\n",
       "      <th>housing_critical</th>\n",
       "      <th>housing_convenient</th>\n",
       "      <th>housing_less_conv</th>\n",
       "      <th>finance_convenient</th>\n",
       "      <th>finance_inconv</th>\n",
       "      <th>health_priority</th>\n",
       "      <th>health_recommended</th>\n",
       "      <th>health_not_recom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>2.000724</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>1.428869</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>1.402427</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.335242</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>1.408503</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>1.978079</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>1.428869</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>1.978079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>1.408503</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>1.432625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>1.402427</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.446341</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.446341</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>2.000724</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>1.428869</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5183 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  children    social  parents_pretentious  parents_great_pret  \\\n",
       "0         1  0.444450 -0.704142             1.434509           -0.713050   \n",
       "1         1  0.444450 -0.704142            -0.697102            1.402427   \n",
       "2         3  1.335242  1.420169             1.434509           -0.713050   \n",
       "3         3  0.444450 -0.704142            -0.697102           -0.713050   \n",
       "4         3  0.444450 -0.704142            -0.697102           -0.713050   \n",
       "...     ...       ...       ...                  ...                 ...   \n",
       "5178      0 -1.337132 -0.704142             1.434509           -0.713050   \n",
       "5179      1 -1.337132  1.420169            -0.697102            1.402427   \n",
       "5180      3 -0.446341  1.420169            -0.697102           -0.713050   \n",
       "5181      1 -0.446341 -0.704142            -0.697102           -0.713050   \n",
       "5182      3 -1.337132  1.420169            -0.697102           -0.713050   \n",
       "\n",
       "      parents_usual  has_nurs_very_crit  has_nurs_improper  has_nurs_proper  \\\n",
       "0         -0.711204            2.000724          -0.499216        -0.500723   \n",
       "1         -0.711204           -0.499819           2.003141        -0.500723   \n",
       "2         -0.711204           -0.499819          -0.499216         1.997111   \n",
       "3          1.406067           -0.499819          -0.499216        -0.500723   \n",
       "4          1.406067           -0.499819          -0.499216         1.997111   \n",
       "...             ...                 ...                ...              ...   \n",
       "5178      -0.711204           -0.499819          -0.499216        -0.500723   \n",
       "5179      -0.711204           -0.499819           2.003141        -0.500723   \n",
       "5180       1.406067           -0.499819           2.003141        -0.500723   \n",
       "5181       1.406067            2.000724          -0.499216        -0.500723   \n",
       "5182       1.406067           -0.499819          -0.499216         1.997111   \n",
       "\n",
       "      has_nurs_critical  ...  form_incomplete  form_foster  housing_critical  \\\n",
       "0             -0.505541  ...        -0.567324    -0.577425          1.428869   \n",
       "1             -0.505541  ...        -0.567324    -0.577425         -0.699854   \n",
       "2             -0.505541  ...        -0.567324    -0.577425         -0.699854   \n",
       "3              1.978079  ...         1.762661    -0.577425         -0.699854   \n",
       "4             -0.505541  ...        -0.567324    -0.577425          1.428869   \n",
       "...                 ...  ...              ...          ...               ...   \n",
       "5178           1.978079  ...        -0.567324    -0.577425         -0.699854   \n",
       "5179          -0.505541  ...         1.762661    -0.577425         -0.699854   \n",
       "5180          -0.505541  ...         1.762661    -0.577425         -0.699854   \n",
       "5181          -0.505541  ...        -0.567324    -0.577425          1.428869   \n",
       "5182          -0.505541  ...         1.762661    -0.577425         -0.699854   \n",
       "\n",
       "      housing_convenient  housing_less_conv  finance_convenient  \\\n",
       "0              -0.711511          -0.709974            0.985252   \n",
       "1               1.405459          -0.709974           -1.014968   \n",
       "2              -0.711511           1.408503           -1.014968   \n",
       "3               1.405459          -0.709974            0.985252   \n",
       "4              -0.711511          -0.709974            0.985252   \n",
       "...                  ...                ...                 ...   \n",
       "5178           -0.711511           1.408503           -1.014968   \n",
       "5179            1.405459          -0.709974           -1.014968   \n",
       "5180            1.405459          -0.709974           -1.014968   \n",
       "5181           -0.711511          -0.709974            0.985252   \n",
       "5182            1.405459          -0.709974            0.985252   \n",
       "\n",
       "      finance_inconv  health_priority  health_recommended  health_not_recom  \n",
       "0          -0.985252         1.399405           -0.708745         -0.698019  \n",
       "1           1.014968         1.399405           -0.708745         -0.698019  \n",
       "2           1.014968        -0.714590            1.410946         -0.698019  \n",
       "3          -0.985252         1.399405           -0.708745         -0.698019  \n",
       "4          -0.985252         1.399405           -0.708745         -0.698019  \n",
       "...              ...              ...                 ...               ...  \n",
       "5178        1.014968        -0.714590           -0.708745          1.432625  \n",
       "5179        1.014968        -0.714590            1.410946         -0.698019  \n",
       "5180        1.014968        -0.714590            1.410946         -0.698019  \n",
       "5181       -0.985252         1.399405           -0.708745         -0.698019  \n",
       "5182       -0.985252        -0.714590            1.410946         -0.698019  \n",
       "\n",
       "[5183 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Nursery_social_prepared_train.csv', sep=',', engine='python')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy:  0.5655864197530864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnClassifier\n",
    "\n",
    "features = df.drop(['label'], axis=1)\n",
    "labels = df.loc[:, 'label']\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(features, labels)\n",
    "\n",
    "art_classifier = ScikitlearnClassifier(model)\n",
    "\n",
    "df_test = pd.read_csv('Nursery_prepared_test.csv', sep=',', engine='python')\n",
    "features_test = df_test.drop(['label'], axis=1)\n",
    "labels_test = df_test.loc[:, 'label']\n",
    "test_data = features_test.to_numpy()\n",
    "\n",
    "print('Base model accuracy: ', model.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "The black-box attack basically trains an additional classifier (called the attack model) to predict the attacked feature's value from the remaining n-1 features as well as the original (attacked) model's predictions.\n",
    "#### Train attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from art.attacks.inference import AttributeInferenceBlackBox\n",
    "\n",
    "attack_feature = 1\n",
    "data = features.to_numpy()\n",
    "\n",
    "# training data without attacked feature\n",
    "x_train_for_attack = np.delete(data, attack_feature, 1)\n",
    "# only attacked feature\n",
    "x_train_feature = data[:, attack_feature].copy().reshape(-1, 1)\n",
    "\n",
    "bb_attack = AttributeInferenceBlackBox(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get original model's predictions\n",
    "x_train_predictions = np.array([np.argmax(arr) for arr in art_classifier.predict(data)]).reshape(-1,1)\n",
    "\n",
    "# train attack model\n",
    "bb_attack.fit(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer sensitive feature and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6326451861856068\n"
     ]
    }
   ],
   "source": [
    "# get inferred values\n",
    "values = [-0.704141531, 1.420169037]\n",
    "inferred_train_bb = bb_attack.infer(x_train_for_attack, x_train_predictions, values=values)\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_bb == x_train_feature.reshape(1,-1)) / len(inferred_train_bb)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that for 63% of the training set, the attacked feature is inferred correctly using this attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential privacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differentially private model accuracy:  0.6087962962962963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/diffprivlib/models/naive_bayes.py:93: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  \"privacy leakage, specify bounds for each dimension.\", PrivacyLeakWarning)\n"
     ]
    }
   ],
   "source": [
    "import diffprivlib.models as dp\n",
    "\n",
    "priv_model = dp.GaussianNB()\n",
    "priv_model.fit(features, labels)\n",
    "\n",
    "priv_art_classifier = ScikitlearnClassifier(priv_model)\n",
    "\n",
    "print('Differentially private model accuracy: ', priv_model.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "### Black-box attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of attack on training data: 0.6156666023538491\n"
     ]
    }
   ],
   "source": [
    "priv_bb_attack = AttributeInferenceBlackBox(priv_art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get original model's predictions\n",
    "priv_x_train_predictions = np.array([np.argmax(arr) for arr in priv_art_classifier.predict(data)]).reshape(-1,1)\n",
    "\n",
    "# train attack model\n",
    "priv_bb_attack.fit(test_data)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_priv_bb = priv_bb_attack.infer(x_train_for_attack, priv_x_train_predictions, values=values)\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_priv_bb == x_train_feature.reshape(1,-1)) / len(inferred_train_priv_bb)\n",
    "print('Accuracy of attack on training data:', train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the precision and recall for each case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.43413597733711046, 0.35681024447031434)\n",
      "(0.3983679525222552, 0.31257275902211873)\n"
     ]
    }
   ],
   "source": [
    "def calc_precision_recall(predicted, actual, positive_value=1):\n",
    "    score = 0  # both predicted and actual are positive\n",
    "    num_positive_predicted = 0  # predicted positive\n",
    "    num_positive_actual = 0  # actual positive\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == positive_value:\n",
    "            num_positive_predicted += 1\n",
    "        if actual[i] == positive_value:\n",
    "            num_positive_actual += 1\n",
    "        if predicted[i] == actual[i]:\n",
    "            if predicted[i] == positive_value:\n",
    "                score += 1\n",
    "    \n",
    "    if num_positive_predicted == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = score / num_positive_predicted  # the fraction of predicted “Yes” responses that are correct\n",
    "    if num_positive_actual == 0:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = score / num_positive_actual  # the fraction of “Yes” responses that are predicted correctly\n",
    "\n",
    "    return precision, recall\n",
    "    \n",
    "# black-box regular\n",
    "print(calc_precision_recall(inferred_train_bb, x_train_feature, positive_value=1.420169037))\n",
    "# black-box differential privacy\n",
    "print(calc_precision_recall(inferred_train_priv_bb, x_train_feature, positive_value=1.420169037))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall remain almost the same, sometimes even slightly increasing.\n",
    "\n",
    "Now let's try with a lower epsilon value (which increases privacy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/diffprivlib/models/naive_bayes.py:93: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  \"privacy leakage, specify bounds for each dimension.\", PrivacyLeakWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differentially private model accuracy:  0.4417438271604938\n",
      "Accuracy of attack on training data: 0.589041095890411\n",
      "Precision and recall for differentially private model: (0.33650793650793653, 0.2467986030267753)\n"
     ]
    }
   ],
   "source": [
    "priv2_model = dp.GaussianNB(epsilon=0.1)\n",
    "priv2_model.fit(features, labels)\n",
    "\n",
    "priv2_art_classifier = ScikitlearnClassifier(priv2_model)\n",
    "\n",
    "print('Differentially private model accuracy: ', priv2_model.score(features_test, labels_test))\n",
    "\n",
    "priv2_bb_attack = AttributeInferenceBlackBox(priv2_art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get original model's predictions\n",
    "priv2_x_train_predictions = np.array([np.argmax(arr) for arr in priv2_art_classifier.predict(data)]).reshape(-1,1)\n",
    "\n",
    "# train attack model\n",
    "priv2_bb_attack.fit(test_data)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_priv2_bb = priv2_bb_attack.infer(x_train_for_attack, priv2_x_train_predictions, values=values)\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_priv2_bb == x_train_feature.reshape(1,-1)) / len(inferred_train_priv2_bb)\n",
    "print('Accuracy of attack on training data:', train_acc)\n",
    "\n",
    "print('Precision and recall for differentially private model:', calc_precision_recall(inferred_train_priv2_bb, x_train_feature, positive_value=1.420169037))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, precision and recall decreased.\n",
    "\n",
    "*You can play with the epsilon value to see how it affects model accuracy and atack accuracy.\n",
    "\n",
    "**Due to the randomness introduced by differential privacy, each run may yield slightly different results even with the same parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
