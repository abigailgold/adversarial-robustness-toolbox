{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running attribute inference attacks on regular and anonymized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show how to run both black-box and white-box inference attacks. This will be demonstarted on the Nursery dataset. \n",
    "\n",
    "The sensitive feature we are trying to infer is the 'social' feature, after we have turned it into a binary feature (the original value 'problematic' receives the new value 1 and the rest 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>children</th>\n",
       "      <th>social</th>\n",
       "      <th>parents_pretentious</th>\n",
       "      <th>parents_great_pret</th>\n",
       "      <th>parents_usual</th>\n",
       "      <th>has_nurs_very_crit</th>\n",
       "      <th>has_nurs_improper</th>\n",
       "      <th>has_nurs_proper</th>\n",
       "      <th>has_nurs_critical</th>\n",
       "      <th>...</th>\n",
       "      <th>form_incomplete</th>\n",
       "      <th>form_foster</th>\n",
       "      <th>housing_critical</th>\n",
       "      <th>housing_convenient</th>\n",
       "      <th>housing_less_conv</th>\n",
       "      <th>finance_convenient</th>\n",
       "      <th>finance_inconv</th>\n",
       "      <th>health_priority</th>\n",
       "      <th>health_recommended</th>\n",
       "      <th>health_not_recom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>2.000724</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>1.428869</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>1.402427</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.335242</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>1.408503</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>1.978079</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>1.428869</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>1.978079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>1.408503</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>1.432625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>1.402427</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.446341</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>-1.014968</td>\n",
       "      <td>1.014968</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.446341</td>\n",
       "      <td>-0.704142</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>2.000724</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567324</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>1.428869</td>\n",
       "      <td>-0.711511</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>1.420169</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762661</td>\n",
       "      <td>-0.577425</td>\n",
       "      <td>-0.699854</td>\n",
       "      <td>1.405459</td>\n",
       "      <td>-0.709974</td>\n",
       "      <td>0.985252</td>\n",
       "      <td>-0.985252</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5183 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  children    social  parents_pretentious  parents_great_pret  \\\n",
       "0         1  0.444450 -0.704142             1.434509           -0.713050   \n",
       "1         1  0.444450 -0.704142            -0.697102            1.402427   \n",
       "2         3  1.335242  1.420169             1.434509           -0.713050   \n",
       "3         3  0.444450 -0.704142            -0.697102           -0.713050   \n",
       "4         3  0.444450 -0.704142            -0.697102           -0.713050   \n",
       "...     ...       ...       ...                  ...                 ...   \n",
       "5178      0 -1.337132 -0.704142             1.434509           -0.713050   \n",
       "5179      1 -1.337132  1.420169            -0.697102            1.402427   \n",
       "5180      3 -0.446341  1.420169            -0.697102           -0.713050   \n",
       "5181      1 -0.446341 -0.704142            -0.697102           -0.713050   \n",
       "5182      3 -1.337132  1.420169            -0.697102           -0.713050   \n",
       "\n",
       "      parents_usual  has_nurs_very_crit  has_nurs_improper  has_nurs_proper  \\\n",
       "0         -0.711204            2.000724          -0.499216        -0.500723   \n",
       "1         -0.711204           -0.499819           2.003141        -0.500723   \n",
       "2         -0.711204           -0.499819          -0.499216         1.997111   \n",
       "3          1.406067           -0.499819          -0.499216        -0.500723   \n",
       "4          1.406067           -0.499819          -0.499216         1.997111   \n",
       "...             ...                 ...                ...              ...   \n",
       "5178      -0.711204           -0.499819          -0.499216        -0.500723   \n",
       "5179      -0.711204           -0.499819           2.003141        -0.500723   \n",
       "5180       1.406067           -0.499819           2.003141        -0.500723   \n",
       "5181       1.406067            2.000724          -0.499216        -0.500723   \n",
       "5182       1.406067           -0.499819          -0.499216         1.997111   \n",
       "\n",
       "      has_nurs_critical  ...  form_incomplete  form_foster  housing_critical  \\\n",
       "0             -0.505541  ...        -0.567324    -0.577425          1.428869   \n",
       "1             -0.505541  ...        -0.567324    -0.577425         -0.699854   \n",
       "2             -0.505541  ...        -0.567324    -0.577425         -0.699854   \n",
       "3              1.978079  ...         1.762661    -0.577425         -0.699854   \n",
       "4             -0.505541  ...        -0.567324    -0.577425          1.428869   \n",
       "...                 ...  ...              ...          ...               ...   \n",
       "5178           1.978079  ...        -0.567324    -0.577425         -0.699854   \n",
       "5179          -0.505541  ...         1.762661    -0.577425         -0.699854   \n",
       "5180          -0.505541  ...         1.762661    -0.577425         -0.699854   \n",
       "5181          -0.505541  ...        -0.567324    -0.577425          1.428869   \n",
       "5182          -0.505541  ...         1.762661    -0.577425         -0.699854   \n",
       "\n",
       "      housing_convenient  housing_less_conv  finance_convenient  \\\n",
       "0              -0.711511          -0.709974            0.985252   \n",
       "1               1.405459          -0.709974           -1.014968   \n",
       "2              -0.711511           1.408503           -1.014968   \n",
       "3               1.405459          -0.709974            0.985252   \n",
       "4              -0.711511          -0.709974            0.985252   \n",
       "...                  ...                ...                 ...   \n",
       "5178           -0.711511           1.408503           -1.014968   \n",
       "5179            1.405459          -0.709974           -1.014968   \n",
       "5180            1.405459          -0.709974           -1.014968   \n",
       "5181           -0.711511          -0.709974            0.985252   \n",
       "5182            1.405459          -0.709974            0.985252   \n",
       "\n",
       "      finance_inconv  health_priority  health_recommended  health_not_recom  \n",
       "0          -0.985252         1.399405           -0.708745         -0.698019  \n",
       "1           1.014968         1.399405           -0.708745         -0.698019  \n",
       "2           1.014968        -0.714590            1.410946         -0.698019  \n",
       "3          -0.985252         1.399405           -0.708745         -0.698019  \n",
       "4          -0.985252         1.399405           -0.708745         -0.698019  \n",
       "...              ...              ...                 ...               ...  \n",
       "5178        1.014968        -0.714590           -0.708745          1.432625  \n",
       "5179        1.014968        -0.714590            1.410946         -0.698019  \n",
       "5180        1.014968        -0.714590            1.410946         -0.698019  \n",
       "5181       -0.985252         1.399405           -0.708745         -0.698019  \n",
       "5182       -0.985252        -0.714590            1.410946         -0.698019  \n",
       "\n",
       "[5183 rows x 23 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Nursery_social_prepared_train.csv', sep=',', engine='python')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnDecisionTreeClassifier\n",
    "\n",
    "features = df.drop(['label'], axis=1)\n",
    "labels = df.loc[:, 'label']\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(features, labels)\n",
    "\n",
    "art_classifier = ScikitlearnDecisionTreeClassifier(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "### Black-box attack\n",
    "The black-box attack basically trains an additional classifier (called the attack model) to predict the attacked feature's value from the remaining n-1 features as well as the original (attacked) model's predictions.\n",
    "#### Train attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from art.attacks.inference import AttributeInferenceBlackBox\n",
    "\n",
    "attack_feature = 1\n",
    "data = features.to_numpy()\n",
    "\n",
    "# training data without attacked feature\n",
    "x_train_for_attack = np.delete(data, attack_feature, 1)\n",
    "# only attacked feature\n",
    "x_train_feature = data[:, attack_feature].copy().reshape(-1, 1)\n",
    "\n",
    "# training data with attacked feature\n",
    "x_train = np.concatenate((x_train_for_attack[:, :attack_feature], x_train_feature), axis=1)\n",
    "x_train = np.concatenate((x_train, x_train_for_attack[:, attack_feature:]), axis=1)\n",
    "\n",
    "bb_attack = AttributeInferenceBlackBox(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get original model's predictions\n",
    "x_train_predictions = np.array([np.argmax(arr) for arr in art_classifier.predict(data)]).reshape(-1,1)\n",
    "\n",
    "# train attack model\n",
    "bb_attack.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer sensitive feature and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7516882114605441\n"
     ]
    }
   ],
   "source": [
    "# get inferred values\n",
    "values = [-0.704141531, 1.420169037]\n",
    "inferred_train_bb = bb_attack.infer(x_train_for_attack, x_train_predictions, values=values)\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_bb == x_train_feature.reshape(1,-1)) / len(inferred_train_bb)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whitebox attacks\n",
    "These two attacks do not train any additional model, they simply use additional information coded within the attacked decision tree model to compute the probability of each value of the attacked feature and outputs the value with the highest probability.\n",
    "### First attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6183677406907196\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.inference import AttributeInferenceWhiteBoxLifestyleDecisionTree\n",
    "\n",
    "wb_attack = AttributeInferenceWhiteBoxLifestyleDecisionTree(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "priors = [3465 / 5183, 1718 / 5183]\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_wb1 = wb_attack.infer(x_train_for_attack, x_train_predictions, values=values, priors=priors)\n",
    "\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_wb1 == x_train_feature.reshape(1,-1)) / len(inferred_train_wb1)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6907196604283233\n"
     ]
    }
   ],
   "source": [
    "from art.attacks.inference import AttributeInferenceWhiteBoxDecisionTree\n",
    "\n",
    "wb2_attack = AttributeInferenceWhiteBoxDecisionTree(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_wb2 = wb2_attack.infer(x_train_for_attack, x_train_predictions, values=values, priors=priors)\n",
    "\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_wb2 == x_train_feature.reshape(1,-1)) / len(inferred_train_wb2)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anonymized data\n",
    "## k=100\n",
    "\n",
    "Now we will apply the same attacks on an anonymized version of the same dataset (k=100). The data has been anonymized on the quasi-identifiers: form, housing, finance, social, health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>children</th>\n",
       "      <th>social</th>\n",
       "      <th>parents_pretentious</th>\n",
       "      <th>parents_great_pret</th>\n",
       "      <th>parents_usual</th>\n",
       "      <th>has_nurs_very_crit</th>\n",
       "      <th>has_nurs_improper</th>\n",
       "      <th>has_nurs_proper</th>\n",
       "      <th>has_nurs_critical</th>\n",
       "      <th>...</th>\n",
       "      <th>form_foster</th>\n",
       "      <th>form_complete</th>\n",
       "      <th>housing_critical</th>\n",
       "      <th>housing_convenient</th>\n",
       "      <th>housing_less_conv</th>\n",
       "      <th>finance_convenient</th>\n",
       "      <th>finance_inconv</th>\n",
       "      <th>health_priority</th>\n",
       "      <th>health_recommended</th>\n",
       "      <th>health_not_recom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.403596</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>2.000724</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464554</td>\n",
       "      <td>-0.952322</td>\n",
       "      <td>0.942423</td>\n",
       "      <td>-0.536975</td>\n",
       "      <td>-0.572078</td>\n",
       "      <td>0.680053</td>\n",
       "      <td>-0.680053</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.403596</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>1.402427</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464554</td>\n",
       "      <td>-0.952322</td>\n",
       "      <td>-1.061095</td>\n",
       "      <td>1.862284</td>\n",
       "      <td>-0.572078</td>\n",
       "      <td>-1.470474</td>\n",
       "      <td>1.470474</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.335242</td>\n",
       "      <td>2.477724</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464554</td>\n",
       "      <td>-0.952322</td>\n",
       "      <td>-1.061095</td>\n",
       "      <td>-0.536975</td>\n",
       "      <td>1.748015</td>\n",
       "      <td>0.680053</td>\n",
       "      <td>-0.680053</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.403596</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>1.978079</td>\n",
       "      <td>...</td>\n",
       "      <td>2.152602</td>\n",
       "      <td>-0.952322</td>\n",
       "      <td>-1.061095</td>\n",
       "      <td>1.862284</td>\n",
       "      <td>-0.572078</td>\n",
       "      <td>0.680053</td>\n",
       "      <td>-0.680053</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>-0.403596</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464554</td>\n",
       "      <td>1.050065</td>\n",
       "      <td>0.942423</td>\n",
       "      <td>-0.536975</td>\n",
       "      <td>-0.572078</td>\n",
       "      <td>0.680053</td>\n",
       "      <td>-0.680053</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>-0.403596</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>1.978079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464554</td>\n",
       "      <td>1.050065</td>\n",
       "      <td>0.942423</td>\n",
       "      <td>-0.536975</td>\n",
       "      <td>-0.572078</td>\n",
       "      <td>0.680053</td>\n",
       "      <td>-0.680053</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>1.432625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>2.477724</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>1.402427</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464554</td>\n",
       "      <td>1.050065</td>\n",
       "      <td>-1.061095</td>\n",
       "      <td>1.862284</td>\n",
       "      <td>-0.572078</td>\n",
       "      <td>-1.470474</td>\n",
       "      <td>1.470474</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.446341</td>\n",
       "      <td>2.477724</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464554</td>\n",
       "      <td>1.050065</td>\n",
       "      <td>-1.061095</td>\n",
       "      <td>1.862284</td>\n",
       "      <td>-0.572078</td>\n",
       "      <td>-1.470474</td>\n",
       "      <td>1.470474</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.446341</td>\n",
       "      <td>-0.403596</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>2.000724</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464554</td>\n",
       "      <td>1.050065</td>\n",
       "      <td>0.942423</td>\n",
       "      <td>-0.536975</td>\n",
       "      <td>-0.572078</td>\n",
       "      <td>0.680053</td>\n",
       "      <td>-0.680053</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>2.477724</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464554</td>\n",
       "      <td>1.050065</td>\n",
       "      <td>-1.061095</td>\n",
       "      <td>1.862284</td>\n",
       "      <td>-0.572078</td>\n",
       "      <td>-1.470474</td>\n",
       "      <td>1.470474</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5183 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  children    social  parents_pretentious  parents_great_pret  \\\n",
       "0         1  0.444450 -0.403596             1.434509           -0.713050   \n",
       "1         1  0.444450 -0.403596            -0.697102            1.402427   \n",
       "2         3  1.335242  2.477724             1.434509           -0.713050   \n",
       "3         3  0.444450 -0.403596            -0.697102           -0.713050   \n",
       "4         3  0.444450 -0.403596            -0.697102           -0.713050   \n",
       "...     ...       ...       ...                  ...                 ...   \n",
       "5178      0 -1.337132 -0.403596             1.434509           -0.713050   \n",
       "5179      1 -1.337132  2.477724            -0.697102            1.402427   \n",
       "5180      3 -0.446341  2.477724            -0.697102           -0.713050   \n",
       "5181      1 -0.446341 -0.403596            -0.697102           -0.713050   \n",
       "5182      3 -1.337132  2.477724            -0.697102           -0.713050   \n",
       "\n",
       "      parents_usual  has_nurs_very_crit  has_nurs_improper  has_nurs_proper  \\\n",
       "0         -0.711204            2.000724          -0.499216        -0.500723   \n",
       "1         -0.711204           -0.499819           2.003141        -0.500723   \n",
       "2         -0.711204           -0.499819          -0.499216         1.997111   \n",
       "3          1.406067           -0.499819          -0.499216        -0.500723   \n",
       "4          1.406067           -0.499819          -0.499216         1.997111   \n",
       "...             ...                 ...                ...              ...   \n",
       "5178      -0.711204           -0.499819          -0.499216        -0.500723   \n",
       "5179      -0.711204           -0.499819           2.003141        -0.500723   \n",
       "5180       1.406067           -0.499819           2.003141        -0.500723   \n",
       "5181       1.406067            2.000724          -0.499216        -0.500723   \n",
       "5182       1.406067           -0.499819          -0.499216         1.997111   \n",
       "\n",
       "      has_nurs_critical  ...  form_foster  form_complete  housing_critical  \\\n",
       "0             -0.505541  ...    -0.464554      -0.952322          0.942423   \n",
       "1             -0.505541  ...    -0.464554      -0.952322         -1.061095   \n",
       "2             -0.505541  ...    -0.464554      -0.952322         -1.061095   \n",
       "3              1.978079  ...     2.152602      -0.952322         -1.061095   \n",
       "4             -0.505541  ...    -0.464554       1.050065          0.942423   \n",
       "...                 ...  ...          ...            ...               ...   \n",
       "5178           1.978079  ...    -0.464554       1.050065          0.942423   \n",
       "5179          -0.505541  ...    -0.464554       1.050065         -1.061095   \n",
       "5180          -0.505541  ...    -0.464554       1.050065         -1.061095   \n",
       "5181          -0.505541  ...    -0.464554       1.050065          0.942423   \n",
       "5182          -0.505541  ...    -0.464554       1.050065         -1.061095   \n",
       "\n",
       "      housing_convenient  housing_less_conv  finance_convenient  \\\n",
       "0              -0.536975          -0.572078            0.680053   \n",
       "1               1.862284          -0.572078           -1.470474   \n",
       "2              -0.536975           1.748015            0.680053   \n",
       "3               1.862284          -0.572078            0.680053   \n",
       "4              -0.536975          -0.572078            0.680053   \n",
       "...                  ...                ...                 ...   \n",
       "5178           -0.536975          -0.572078            0.680053   \n",
       "5179            1.862284          -0.572078           -1.470474   \n",
       "5180            1.862284          -0.572078           -1.470474   \n",
       "5181           -0.536975          -0.572078            0.680053   \n",
       "5182            1.862284          -0.572078           -1.470474   \n",
       "\n",
       "      finance_inconv  health_priority  health_recommended  health_not_recom  \n",
       "0          -0.680053         1.399405           -0.708745         -0.698019  \n",
       "1           1.470474         1.399405           -0.708745         -0.698019  \n",
       "2          -0.680053        -0.714590            1.410946         -0.698019  \n",
       "3          -0.680053         1.399405           -0.708745         -0.698019  \n",
       "4          -0.680053         1.399405           -0.708745         -0.698019  \n",
       "...              ...              ...                 ...               ...  \n",
       "5178       -0.680053        -0.714590           -0.708745          1.432625  \n",
       "5179        1.470474        -0.714590            1.410946         -0.698019  \n",
       "5180        1.470474        -0.714590            1.410946         -0.698019  \n",
       "5181       -0.680053         1.399405           -0.708745         -0.698019  \n",
       "5182        1.470474        -0.714590            1.410946         -0.698019  \n",
       "\n",
       "[5183 rows x 23 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anon_df = pd.read_csv('Nursery_anonymized_prepared_train.csv', sep=',', engine='python')\n",
    "\n",
    "anon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4479"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique rows in original data\n",
    "len(df.drop_duplicates().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1079"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique rows in anonymized data\n",
    "len(anon_df.drop_duplicates().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "anon_features = anon_df.drop(['label'], axis=1)\n",
    "anon_labels = anon_df.loc[:, 'label']\n",
    "anon_model = DecisionTreeClassifier()\n",
    "anon_model.fit(anon_features, anon_labels)\n",
    "\n",
    "anon_art_classifier = ScikitlearnDecisionTreeClassifier(anon_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "### Black-box attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7457071194289022\n"
     ]
    }
   ],
   "source": [
    "anon_bb_attack = AttributeInferenceBlackBox(anon_art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get original model's predictions\n",
    "anon_x_train_predictions = np.array([np.argmax(arr) for arr in art_classifier.predict(data)]).reshape(-1,1)\n",
    "\n",
    "# train attack model\n",
    "anon_bb_attack.fit(x_train)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_anon_bb = anon_bb_attack.infer(x_train_for_attack, anon_x_train_predictions, values=values)\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_anon_bb == x_train_feature.reshape(1,-1)) / len(inferred_train_anon_bb)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White box attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6143160331854138\n"
     ]
    }
   ],
   "source": [
    "anon_wb_attack = AttributeInferenceWhiteBoxLifestyleDecisionTree(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_anon_wb1 = anon_wb_attack.infer(x_train_for_attack, anon_x_train_predictions, values=values, priors=priors)\n",
    "\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_anon_wb1 == x_train_feature.reshape(1,-1)) / len(inferred_train_anon_wb1)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703260659849508\n"
     ]
    }
   ],
   "source": [
    "anon_wb2_attack = AttributeInferenceWhiteBoxDecisionTree(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_anon_wb2 = anon_wb2_attack.infer(x_train_for_attack, anon_x_train_predictions, values=values, priors=priors)\n",
    "\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_anon_wb2 == x_train_feature.reshape(1,-1)) / len(inferred_train_anon_wb2)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the whitebox attacks has slightly increased. This may be due to the fact that the prior distribution of the larger class has increased (from 0.67 to 0.85). Let's check the precision and recall for each case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7270811380400422, 0.40162980209545984)\n",
      "(0.7261146496815286, 0.3981373690337602)\n"
     ]
    }
   ],
   "source": [
    "def calc_precision_recall(predicted, actual, positive_value=1):\n",
    "    score = 0  # both predicted and actual are positive\n",
    "    num_positive_predicted = 0  # predicted positive\n",
    "    num_positive_actual = 0  # actual positive\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == positive_value:\n",
    "            num_positive_predicted += 1\n",
    "        if actual[i] == positive_value:\n",
    "            num_positive_actual += 1\n",
    "        if predicted[i] == actual[i]:\n",
    "            if predicted[i] == positive_value:\n",
    "                score += 1\n",
    "    \n",
    "    if num_positive_predicted == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = score / num_positive_predicted  # the fraction of predicted “Yes” responses that are correct\n",
    "    if num_positive_actual == 0:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = score / num_positive_actual  # the fraction of “Yes” responses that are predicted correctly\n",
    "\n",
    "    return precision, recall\n",
    "    \n",
    "# black-box regular\n",
    "print(calc_precision_recall(inferred_train_bb, x_train_feature, positive_value=1.420169037))\n",
    "# black-box anonymized\n",
    "print(calc_precision_recall(inferred_train_anon_bb, x_train_feature, positive_value=1.420169037))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3402948402948403, 0.1612339930151339)\n",
      "(0.3426651735722284, 0.1781140861466822)\n",
      "(0.5880551301684533, 0.22351571594877764)\n",
      "(0.6480263157894737, 0.22933643771827705)\n"
     ]
    }
   ],
   "source": [
    "# white-box 1 regular\n",
    "print(calc_precision_recall(inferred_train_wb1, x_train_feature, positive_value=1.420169037))\n",
    "# white-box 1 anonymized\n",
    "print(calc_precision_recall(inferred_train_anon_wb1, x_train_feature, positive_value=1.420169037))\n",
    "\n",
    "# white-box 2 regular\n",
    "print(calc_precision_recall(inferred_train_wb2, x_train_feature, positive_value=1.420169037))\n",
    "# white-box 2 anonymized\n",
    "print(calc_precision_recall(inferred_train_anon_wb2, x_train_feature, positive_value=1.420169037))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k=1000\n",
    "\n",
    "Now we apply the attacks on an anonymized version of the same dataset (k=1000). The data has been anonymized on the quasi-identifiers: form, housing, finance, social, health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>children</th>\n",
       "      <th>social</th>\n",
       "      <th>parents_pretentious</th>\n",
       "      <th>parents_great_pret</th>\n",
       "      <th>parents_usual</th>\n",
       "      <th>has_nurs_very_crit</th>\n",
       "      <th>has_nurs_improper</th>\n",
       "      <th>has_nurs_proper</th>\n",
       "      <th>has_nurs_critical</th>\n",
       "      <th>...</th>\n",
       "      <th>form_completed.1</th>\n",
       "      <th>form_complete</th>\n",
       "      <th>housing_convenient</th>\n",
       "      <th>housing_less_conv</th>\n",
       "      <th>housing_critical</th>\n",
       "      <th>finance_inconv</th>\n",
       "      <th>finance_convenient</th>\n",
       "      <th>health_priority</th>\n",
       "      <th>health_recommended</th>\n",
       "      <th>health_not_recom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>0</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>2.000724</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-1.399405</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>1.402427</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-1.399405</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.335242</td>\n",
       "      <td>0</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>0.714590</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>1.978079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-1.399405</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-1.399405</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.434509</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>1.978079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>1.432625</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>1.432625</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>0.714590</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>1.432625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>1.402427</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>0.714590</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5180</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.446341</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>2.003141</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>0.714590</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.446341</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>2.000724</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>-0.500723</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-1.399405</td>\n",
       "      <td>1.399405</td>\n",
       "      <td>-0.708745</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.337132</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.697102</td>\n",
       "      <td>-0.713050</td>\n",
       "      <td>1.406067</td>\n",
       "      <td>-0.499819</td>\n",
       "      <td>-0.499216</td>\n",
       "      <td>1.997111</td>\n",
       "      <td>-0.505541</td>\n",
       "      <td>...</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>0.714590</td>\n",
       "      <td>-0.714590</td>\n",
       "      <td>1.410946</td>\n",
       "      <td>-0.698019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5183 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  children  social  parents_pretentious  parents_great_pret  \\\n",
       "0         4  0.444450       0             1.434509           -0.713050   \n",
       "1         4  0.444450       0            -0.697102            1.402427   \n",
       "2         3  1.335242       0             1.434509           -0.713050   \n",
       "3         3  0.444450       0            -0.697102           -0.713050   \n",
       "4         3  0.444450       0            -0.697102           -0.713050   \n",
       "...     ...       ...     ...                  ...                 ...   \n",
       "5178      0 -1.337132       0             1.434509           -0.713050   \n",
       "5179      4 -1.337132       0            -0.697102            1.402427   \n",
       "5180      3 -0.446341       0            -0.697102           -0.713050   \n",
       "5181      4 -0.446341       0            -0.697102           -0.713050   \n",
       "5182      3 -1.337132       0            -0.697102           -0.713050   \n",
       "\n",
       "      parents_usual  has_nurs_very_crit  has_nurs_improper  has_nurs_proper  \\\n",
       "0         -0.711204            2.000724          -0.499216        -0.500723   \n",
       "1         -0.711204           -0.499819           2.003141        -0.500723   \n",
       "2         -0.711204           -0.499819          -0.499216         1.997111   \n",
       "3          1.406067           -0.499819          -0.499216        -0.500723   \n",
       "4          1.406067           -0.499819          -0.499216         1.997111   \n",
       "...             ...                 ...                ...              ...   \n",
       "5178      -0.711204           -0.499819          -0.499216        -0.500723   \n",
       "5179      -0.711204           -0.499819           2.003141        -0.500723   \n",
       "5180       1.406067           -0.499819           2.003141        -0.500723   \n",
       "5181       1.406067            2.000724          -0.499216        -0.500723   \n",
       "5182       1.406067           -0.499819          -0.499216         1.997111   \n",
       "\n",
       "      has_nurs_critical  ...  form_completed.1  form_complete  \\\n",
       "0             -0.505541  ...         -0.708745      -0.698019   \n",
       "1             -0.505541  ...         -0.708745      -0.698019   \n",
       "2             -0.505541  ...          1.410946      -0.698019   \n",
       "3              1.978079  ...         -0.708745      -0.698019   \n",
       "4             -0.505541  ...         -0.708745      -0.698019   \n",
       "...                 ...  ...               ...            ...   \n",
       "5178           1.978079  ...         -0.708745       1.432625   \n",
       "5179          -0.505541  ...          1.410946      -0.698019   \n",
       "5180          -0.505541  ...          1.410946      -0.698019   \n",
       "5181          -0.505541  ...         -0.708745      -0.698019   \n",
       "5182          -0.505541  ...          1.410946      -0.698019   \n",
       "\n",
       "      housing_convenient  housing_less_conv  housing_critical  finance_inconv  \\\n",
       "0               1.399405          -0.708745         -0.698019        1.399405   \n",
       "1               1.399405          -0.708745         -0.698019        1.399405   \n",
       "2              -0.714590           1.410946         -0.698019       -0.714590   \n",
       "3               1.399405          -0.708745         -0.698019        1.399405   \n",
       "4               1.399405          -0.708745         -0.698019        1.399405   \n",
       "...                  ...                ...               ...             ...   \n",
       "5178           -0.714590          -0.708745          1.432625       -0.714590   \n",
       "5179           -0.714590           1.410946         -0.698019       -0.714590   \n",
       "5180           -0.714590           1.410946         -0.698019       -0.714590   \n",
       "5181            1.399405          -0.708745         -0.698019        1.399405   \n",
       "5182           -0.714590           1.410946         -0.698019       -0.714590   \n",
       "\n",
       "      finance_convenient  health_priority  health_recommended  \\\n",
       "0              -1.399405         1.399405           -0.708745   \n",
       "1              -1.399405         1.399405           -0.708745   \n",
       "2               0.714590        -0.714590            1.410946   \n",
       "3              -1.399405         1.399405           -0.708745   \n",
       "4              -1.399405         1.399405           -0.708745   \n",
       "...                  ...              ...                 ...   \n",
       "5178            0.714590        -0.714590           -0.708745   \n",
       "5179            0.714590        -0.714590            1.410946   \n",
       "5180            0.714590        -0.714590            1.410946   \n",
       "5181           -1.399405         1.399405           -0.708745   \n",
       "5182            0.714590        -0.714590            1.410946   \n",
       "\n",
       "      health_not_recom  \n",
       "0            -0.698019  \n",
       "1            -0.698019  \n",
       "2            -0.698019  \n",
       "3            -0.698019  \n",
       "4            -0.698019  \n",
       "...                ...  \n",
       "5178          1.432625  \n",
       "5179         -0.698019  \n",
       "5180         -0.698019  \n",
       "5181         -0.698019  \n",
       "5182         -0.698019  \n",
       "\n",
       "[5183 rows x 23 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anon2_df = pd.read_csv('Nursery_anonymized1000_prepared_train.csv', sep=',', engine='python')\n",
    "\n",
    "anon2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique rows in anonymized data\n",
    "len(anon2_df.drop_duplicates().index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "anon2_features = anon_df.drop(['label'], axis=1)\n",
    "anon2_labels = anon_df.loc[:, 'label']\n",
    "anon2_model = DecisionTreeClassifier()\n",
    "anon2_model.fit(anon2_features, anon2_labels)\n",
    "\n",
    "anon2_art_classifier = ScikitlearnDecisionTreeClassifier(anon2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "### Black-box attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7430059810920316\n"
     ]
    }
   ],
   "source": [
    "anon2_bb_attack = AttributeInferenceBlackBox(anon2_art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get original model's predictions\n",
    "anon2_x_train_predictions = np.array([np.argmax(arr) for arr in art_classifier.predict(data)]).reshape(-1,1)\n",
    "\n",
    "# train attack model\n",
    "anon2_bb_attack.fit(x_train)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_anon_bb = anon2_bb_attack.infer(x_train_for_attack, anon2_x_train_predictions, values=values)\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_anon_bb == x_train_feature.reshape(1,-1)) / len(inferred_train_anon_bb)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White box attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6143160331854138\n"
     ]
    }
   ],
   "source": [
    "anon2_wb_attack = AttributeInferenceWhiteBoxLifestyleDecisionTree(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_anon_wb1 = anon2_wb_attack.infer(x_train_for_attack, anon2_x_train_predictions, values=values, priors=priors)\n",
    "\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_anon_wb1 == x_train_feature.reshape(1,-1)) / len(inferred_train_anon_wb1)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703260659849508\n"
     ]
    }
   ],
   "source": [
    "anon2_wb2_attack = AttributeInferenceWhiteBoxDecisionTree(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_anon_wb2 = anon2_wb2_attack.infer(x_train_for_attack, anon2_x_train_predictions, values=values, priors=priors)\n",
    "\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_anon_wb2 == x_train_feature.reshape(1,-1)) / len(inferred_train_anon_wb2)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, the accuracy of the attacks has slightly increased. Let's check the precision and recall for each case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.743801652892562, 0.36670547147846333)\n",
      "(0.6131498470948012, 0.23341094295692666)\n",
      "(0.3402948402948403, 0.1612339930151339)\n",
      "(1, 0.0)\n",
      "(0.5880551301684533, 0.22351571594877764)\n",
      "(1, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# black-box regular\n",
    "print(calc_precision_recall(inferred_train_bb, x_train_feature, positive_value=1.420169037))\n",
    "# black-box anonymized\n",
    "print(calc_precision_recall(inferred_train_anon_bb, x_train_feature, positive_value=1.420169037))\n",
    "\n",
    "# white-box 1 regular\n",
    "print(calc_precision_recall(inferred_train_wb1, x_train_feature, positive_value=1.420169037))\n",
    "# white-box 1 anonymized\n",
    "print(calc_precision_recall(inferred_train_anon_wb1, x_train_feature, positive_value=1.420169037))\n",
    "\n",
    "# white-box 2 regular\n",
    "print(calc_precision_recall(inferred_train_wb2, x_train_feature, positive_value=1.420169037))\n",
    "# white-box 2 anonymized\n",
    "print(calc_precision_recall(inferred_train_anon_wb2, x_train_feature, positive_value=1.420169037))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In the anonymized version of the white-box attacks, no records were predicted with the positive value for the attacked feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
