{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running ART attribute inference attacks on regular and differentially private models created using DiffPrivLib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show how to run attribute inference attacks on models trained using differential privacy. This will be demonstrated on the iris dataset (https://archive.ics.uci.edu/ml/datasets/iris), with a Naive Bayes classifier trained using the IBM Differential Privacy Library (https://github.com/IBM/differential-privacy-library)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset = datasets.load_iris()\n",
    "x_train_iris, x_test_iris, y_train_iris, y_test_iris = train_test_split(dataset.data, dataset.target, test_size=0.2)\n",
    "\n",
    "attack_feature = 2  # petal length\n",
    "\n",
    "# need to transform attacked feature into categorical\n",
    "def transform_feature(x):\n",
    "    x[x <= 2] = 0.0\n",
    "    x[(x > 2) & (x <= 5)] = 1.0\n",
    "    x[x > 5] = 2.0\n",
    "\n",
    "values = [0.0, 1.0, 2.0]\n",
    "\n",
    "# training data without attacked feature\n",
    "x_train_for_attack = np.delete(x_train_iris, attack_feature, 1)\n",
    "# only attacked feature\n",
    "x_train_feature = x_train_iris[:, attack_feature].copy().reshape(-1, 1)\n",
    "transform_feature(x_train_feature)\n",
    "# training data with attacked feature (after transformation)\n",
    "x_train = np.concatenate((x_train_for_attack[:, :attack_feature], x_train_feature), axis=1)\n",
    "x_train = np.concatenate((x_train, x_train_for_attack[:, attack_feature:]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnClassifier\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train_iris)\n",
    "\n",
    "art_classifier = ScikitlearnClassifier(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "### Black-box attack\n",
    "The black-box attack basically trains an additional classifier (called the attack model) to predict the attacked feature's value from the remaining n-1 features as well as the original (attacked) model's predictions.\n",
    "#### Train attack model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from art.attacks.inference import AttributeInferenceBlackBox\n",
    "\n",
    "bb_attack = AttributeInferenceBlackBox(art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get original model's predictions\n",
    "x_train_predictions = np.array([np.argmax(arr) for arr in art_classifier.predict(x_train)]).reshape(-1,1)\n",
    "\n",
    "# train attack model\n",
    "bb_attack.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infer sensitive feature and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of attack on training data: 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "# get inferred values\n",
    "inferred_train_bb = bb_attack.infer(x_train_for_attack, x_train_predictions, values=values)\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_bb == x_train_feature.reshape(1,-1)) / len(inferred_train_bb)\n",
    "print('Accuracy of attack on training data:', train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that for 99% of the test set, the attacked feature is inferred correctly using this attack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentially private model\n",
    "\n",
    "Now we will apply the same attacks on a differentially private model trained using the diffprivlib library, with the default parameters (epsilon=1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/diffprivlib/models/naive_bayes.py:93: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  \"privacy leakage, specify bounds for each dimension.\", PrivacyLeakWarning)\n"
     ]
    }
   ],
   "source": [
    "import diffprivlib.models as dp\n",
    "\n",
    "priv_model = dp.GaussianNB()\n",
    "priv_model.fit(x_train, y_train_iris)\n",
    "\n",
    "priv_art_classifier = ScikitlearnClassifier(priv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack\n",
    "### Black-box attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of attack on training data: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "priv_bb_attack = AttributeInferenceBlackBox(priv_art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get original model's predictions\n",
    "priv_x_train_predictions = np.array([np.argmax(arr) for arr in priv_art_classifier.predict(x_train)]).reshape(-1,1)\n",
    "\n",
    "# train attack model\n",
    "priv_bb_attack.fit(x_train)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_priv_bb = priv_bb_attack.infer(x_train_for_attack, priv_x_train_predictions, values=values)\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_priv_bb == x_train_feature.reshape(1,-1)) / len(inferred_train_priv_bb)\n",
    "print('Accuracy of attack on training data:', train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy has decreased slightly. Now let's check the precision and recall (we use the value of 2.0 as the positive value in this case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision and recall for regular model: (0.9705882352941176, 1.0)\n",
      "Precision and recall for differentially private model: (0.8787878787878788, 0.8787878787878788)\n"
     ]
    }
   ],
   "source": [
    "def calc_precision_recall(predicted, actual, positive_value=1):\n",
    "    score = 0  # both predicted and actual are positive\n",
    "    num_positive_predicted = 0  # predicted positive\n",
    "    num_positive_actual = 0  # actual positive\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == positive_value:\n",
    "            num_positive_predicted += 1\n",
    "        if actual[i] == positive_value:\n",
    "            num_positive_actual += 1\n",
    "        if predicted[i] == actual[i]:\n",
    "            if predicted[i] == positive_value:\n",
    "                score += 1\n",
    "    \n",
    "    if num_positive_predicted == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = score / num_positive_predicted  # the fraction of predicted “Yes” responses that are correct\n",
    "    if num_positive_actual == 0:\n",
    "        recall = 1\n",
    "    else:\n",
    "        recall = score / num_positive_actual  # the fraction of “Yes” responses that are predicted correctly\n",
    "\n",
    "    return precision, recall\n",
    "    \n",
    "# black-box regular\n",
    "print('Precision and recall for regular model:', calc_precision_recall(inferred_train_bb, x_train_feature, positive_value=2))\n",
    "# black-box differential privacy\n",
    "print('Precision and recall for differentially private model:', calc_precision_recall(inferred_train_priv_bb, x_train_feature, positive_value=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision and recall decrease slightly.\n",
    "\n",
    "Now let's try with a lower epsilon value (which increases privacy) and specify the bounds for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of attack on training data: 0.925\n",
      "Precision and recall for differentially private model: (0.8787878787878788, 0.8787878787878788)\n"
     ]
    }
   ],
   "source": [
    "bounds = [(4.3, 7.9), (2.0, 4.4), (0.0, 2.0), (0.1, 2.5)]\n",
    "\n",
    "priv2_model = dp.GaussianNB(epsilon=0.01, bounds=bounds)\n",
    "priv2_model.fit(x_train, y_train_iris)\n",
    "\n",
    "priv2_art_classifier = ScikitlearnClassifier(priv2_model)\n",
    "\n",
    "priv2_bb_attack = AttributeInferenceBlackBox(priv2_art_classifier, attack_feature=attack_feature)\n",
    "\n",
    "# get original model's predictions\n",
    "priv2_x_train_predictions = np.array([np.argmax(arr) for arr in priv2_art_classifier.predict(x_train)]).reshape(-1,1)\n",
    "\n",
    "# train attack model\n",
    "priv2_bb_attack.fit(x_train)\n",
    "\n",
    "# get inferred values\n",
    "inferred_train_priv2_bb = priv2_bb_attack.infer(x_train_for_attack, priv2_x_train_predictions, values=values)\n",
    "# check accuracy\n",
    "train_acc = np.sum(inferred_train_priv2_bb == x_train_feature.reshape(1,-1)) / len(inferred_train_priv2_bb)\n",
    "print('Accuracy of attack on training data:', train_acc)\n",
    "\n",
    "print('Precision and recall for differentially private model:', calc_precision_recall(inferred_train_priv2_bb, x_train_feature, positive_value=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, precision and recall are further decreased."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
